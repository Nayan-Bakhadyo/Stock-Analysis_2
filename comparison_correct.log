2025-12-01 11:51:51.218827: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro
2025-12-01 11:51:51.218860: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB
2025-12-01 11:51:51.218865: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB
2025-12-01 11:51:51.218896: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2025-12-01 11:51:51.218915: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
2025-12-01 11:51:53.958191: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.


================================================================================
Using STANDARD single-point predictions
================================================================================


================================================================================
COMPARING LSTM vs xLSTM - PFL
================================================================================
Horizons: [1, 3, 5, 10, 15, 21]
LSTM epochs: 30
xLSTM epochs: 50, hidden: 512, blocks: 7
================================================================================

================================================================================
TRAINING LSTM (TensorFlow) - Multi-Horizon
================================================================================
âœ“ Loaded 600 days of data
  Date range: 2023-04-12 to 2025-11-27

--- Training LSTM for 1-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.077158
âœ“ Validation MAE: 0.041390
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.01%, Direction Acc: 0.0%

--- Training LSTM for 3-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.240193
âœ“ Validation MAE: 0.102764
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.03%, Direction Acc: 0.0%

--- Training LSTM for 5-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.098109
âœ“ Validation MAE: 0.068292
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.02%, Direction Acc: 0.0%

--- Training LSTM for 10-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.133979
âœ“ Validation MAE: 0.054822
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.01%, Direction Acc: 0.0%

--- Training LSTM for 15-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.240522
âœ“ Validation MAE: 0.151423
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.04%, Direction Acc: 0.0%

--- Training LSTM for 21-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.190269
âœ“ Validation MAE: 0.109059
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.03%, Direction Acc: 0.0%

âœ“ LSTM training completed in 123.60s

================================================================================
TRAINING xLSTM (PyTorch) - Multi-Horizon
================================================================================
âœ“ Loaded 900 days of data
  Date range: 2022-01-09 to 2025-11-27

âœ“ Data prepared
  Train samples: 631
  Test samples: 158
  Horizons: [1, 3, 5, 10, 15, 21]

âœ“ Using device: mps
Building xLSTM forecaster:
  Hidden size: 512
  Num blocks: 7
  Num heads: 8
  Horizons: [1, 3, 5, 10, 15, 21]
Building xLSTM forecaster:
  Hidden size: 512
  Num blocks: 7
  Num heads: 8
  Horizons: [1, 3, 5, 10, 15, 21]
âœ“ Model created - 12,482,678 parameters

================================================================================
Training for 50 epochs...
================================================================================


Epoch 10/50
  Train Loss: 0.386818
  Val Loss: 0.030918
  Horizon MAE:
     1-day: 0.0689
     3-day: 0.0636
     5-day: 0.0611
    10-day: 0.0624
    15-day: 0.0660
    21-day: 0.0852

Early stopping at epoch 17

================================================================================
Evaluating model...
================================================================================

Horizon  1 days: MAE=24.7615, MAPE=6.04%, RMSE=29.0811, RÂ²=-0.3458
Horizon  3 days: MAE=24.9185, MAPE=6.09%, RMSE=29.2109, RÂ²=-0.3510
Horizon  5 days: MAE=27.3822, MAPE=6.72%, RMSE=31.6538, RÂ²=-0.5836
Horizon 10 days: MAE=30.4820, MAPE=7.54%, RMSE=34.8027, RÂ²=-1.1851
Horizon 15 days: MAE=35.1123, MAPE=8.76%, RMSE=39.5116, RÂ²=-2.2428
Horizon 21 days: MAE=31.3431, MAPE=7.89%, RMSE=35.9726, RÂ²=-2.3071

âœ“ xLSTM training completed in 173.23s

================================================================================
COMPARISON RESULTS - PFL
================================================================================

Model Parameters:
  LSTM:  N/A (TensorFlow)
  xLSTM: 12,482,678

Training Time:
  LSTM:  123.60s
  xLSTM: 173.23s

================================================================================
PERFORMANCE METRICS: MAPE (Lower is Better)
================================================================================
Horizon    LSTM MAPE    xLSTM MAPE   Winner    
--------------------------------------------------
1                0.01%        6.04%  LSTM      
3                0.03%        6.09%  LSTM      
5                0.02%        6.72%  LSTM      
10               0.01%        7.54%  LSTM      
15               0.04%        8.76%  LSTM      
21               0.03%        7.89%  LSTM      

================================================================================
PERFORMANCE METRICS: RMSE (Lower is Better)
================================================================================
Horizon    xLSTM RMSE     
------------------------------
1               29.0811
3               29.2109
5               31.6538
10              34.8027
15              39.5116
21              35.9726

================================================================================
PERFORMANCE METRICS: RÂ² (Higher is Better, max=1.0)
================================================================================
Horizon    xLSTM RÂ²       
------------------------------
1               -0.3458
3               -0.3510
5               -0.5836
10              -1.1851
15              -2.2428
21              -2.3071

âœ“ Comparison saved to: model_comparisons/PFL_comparison_20251201_115648.json

