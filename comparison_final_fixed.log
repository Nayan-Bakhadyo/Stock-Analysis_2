2025-12-01 11:42:30.385774: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro
2025-12-01 11:42:30.385804: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB
2025-12-01 11:42:30.385810: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB
2025-12-01 11:42:30.385842: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2025-12-01 11:42:30.385856: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
2025-12-01 11:42:33.055812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.


================================================================================
Using STANDARD single-point predictions
================================================================================


================================================================================
COMPARING LSTM vs xLSTM - PFL
================================================================================
Horizons: [1, 3, 5, 10, 15, 21]
LSTM epochs: 30
xLSTM epochs: 50, hidden: 512, blocks: 7
================================================================================

================================================================================
TRAINING LSTM (TensorFlow) - Multi-Horizon
================================================================================
âœ“ Loaded 600 days of data
  Date range: 2023-04-12 to 2025-11-27

--- Training LSTM for 1-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.080647
âœ“ Validation MAE: 0.043802
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.01%, Direction Acc: 0.0%

--- Training LSTM for 3-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.099080
âœ“ Validation MAE: 0.066011
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.02%, Direction Acc: 0.0%

--- Training LSTM for 5-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.103848
âœ“ Validation MAE: 0.063424
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.02%, Direction Acc: 0.0%

--- Training LSTM for 10-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.240508
âœ“ Validation MAE: 0.134156
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.03%, Direction Acc: 0.0%

--- Training LSTM for 15-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.094712
âœ“ Validation MAE: 0.052006
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.01%, Direction Acc: 0.0%

--- Training LSTM for 21-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.083083
âœ“ Validation MAE: 0.050466
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.01%, Direction Acc: 0.0%

âœ“ LSTM training completed in 158.04s

================================================================================
TRAINING xLSTM (PyTorch) - Multi-Horizon
================================================================================
âœ“ Loaded 900 days of data
  Date range: 2022-01-09 to 2025-11-27

âœ“ Data prepared
  Train samples: 631
  Test samples: 158
  Horizons: [1, 3, 5, 10, 15, 21]

âœ“ Using device: mps
Building xLSTM forecaster:
  Hidden size: 512
  Num blocks: 7
  Num heads: 8
  Horizons: [1, 3, 5, 10, 15, 21]
Building xLSTM forecaster:
  Hidden size: 512
  Num blocks: 7
  Num heads: 8
  Horizons: [1, 3, 5, 10, 15, 21]
âœ“ Model created - 12,482,678 parameters

================================================================================
Training for 50 epochs...
================================================================================


Epoch 10/50
  Train Loss: 0.389333
  Val Loss: 0.017212
  Horizon MAE:
     1-day: 0.0434
     3-day: 0.0462
     5-day: 0.0409
    10-day: 0.0495
    15-day: 0.0536
    21-day: 0.0548

Epoch 20/50
  Train Loss: 0.384254
  Val Loss: 0.026162
  Horizon MAE:
     1-day: 0.0588
     3-day: 0.0577
     5-day: 0.0527
    10-day: 0.0686
    15-day: 0.0644
    21-day: 0.0709

Early stopping at epoch 21

================================================================================
Evaluating model...
================================================================================

Horizon  1 days: MAE=0.0513, MAPE=22.67%, RMSE=0.0602, RÂ²=-0.3059
Horizon  3 days: MAE=0.0484, MAPE=21.19%, RMSE=0.0575, RÂ²=-0.1842
Horizon  5 days: MAE=0.0517, MAPE=22.91%, RMSE=0.0607, RÂ²=-0.3185
Horizon 10 days: MAE=0.0516, MAPE=23.45%, RMSE=0.0605, RÂ²=-0.4984
Horizon 15 days: MAE=0.0498, MAPE=23.45%, RMSE=0.0588, RÂ²=-0.6266
Horizon 21 days: MAE=0.0516, MAPE=25.18%, RMSE=0.0609, RÂ²=-1.1449

âœ“ xLSTM training completed in 213.61s

================================================================================
COMPARISON RESULTS - PFL
================================================================================

Model Parameters:
  LSTM:  N/A (TensorFlow)
  xLSTM: 12,482,678

Training Time:
  LSTM:  158.04s
  xLSTM: 213.61s

================================================================================
PERFORMANCE METRICS: MAPE (Lower is Better)
================================================================================
Horizon    LSTM MAPE    xLSTM MAPE   Winner    
--------------------------------------------------
1                0.01%       22.67%  LSTM      
3                0.02%       21.19%  LSTM      
5                0.02%       22.91%  LSTM      
10               0.03%       23.45%  LSTM      
15               0.01%       23.45%  LSTM      
21               0.01%       25.18%  LSTM      

================================================================================
PERFORMANCE METRICS: RMSE (Lower is Better)
================================================================================
Horizon    xLSTM RMSE     
------------------------------
1                0.0602
3                0.0575
5                0.0607
10               0.0605
15               0.0588
21               0.0609

================================================================================
PERFORMANCE METRICS: RÂ² (Higher is Better, max=1.0)
================================================================================
Horizon    xLSTM RÂ²       
------------------------------
1               -0.3059
3               -0.1842
5               -0.3185
10              -0.4984
15              -0.6266
21              -1.1449

âœ“ Comparison saved to: model_comparisons/PFL_comparison_20251201_114842.json

