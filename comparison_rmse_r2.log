2025-12-01 11:18:03.753476: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro
2025-12-01 11:18:03.753508: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB
2025-12-01 11:18:03.753514: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB
2025-12-01 11:18:03.753841: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2025-12-01 11:18:03.754017: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
2025-12-01 11:18:06.597753: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.
Traceback (most recent call last):
  File "/Users/Nayan/Documents/Business/Stock_Analysis/compare_lstm_xlstm_fixed.py", line 445, in <module>
    comparison = compare_models(
                 ^^^^^^^^^^^^^^^
  File "/Users/Nayan/Documents/Business/Stock_Analysis/compare_lstm_xlstm_fixed.py", line 346, in compare_models
    xlstm_results = train_xlstm_multi_horizon(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/Nayan/Documents/Business/Stock_Analysis/compare_lstm_xlstm_fixed.py", line 239, in train_xlstm_multi_horizon
    print(f"âœ“ Model created - {model.get_num_parameters():,} parameters")
                               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/Nayan/anaconda3/envs/Stock_Prediction/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1964, in __getattr__
    raise AttributeError(
AttributeError: 'xLSTMStockForecaster' object has no attribute 'get_num_parameters'. Did you mean: 'get_parameter'?

ERROR conda.cli.main_run:execute(49): `conda run python3 compare_lstm_xlstm_fixed.py PFL --horizons 1 3 5 10 15 21 --lstm-epochs 30 --xlstm-epochs 50 --xlstm-hidden 512 --xlstm-blocks 7` failed. (See above for error)

================================================================================
COMPARING LSTM vs xLSTM - PFL
================================================================================
Horizons: [1, 3, 5, 10, 15, 21]
LSTM epochs: 30
xLSTM epochs: 50, hidden: 512, blocks: 7
================================================================================

================================================================================
TRAINING LSTM (TensorFlow) - Multi-Horizon
================================================================================
âœ“ Loaded 600 days of data
  Date range: 2023-04-12 to 2025-11-27

--- Training LSTM for 1-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.084110
âœ“ Validation MAE: 0.045175
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.01%, Direction Acc: 0.0%

--- Training LSTM for 3-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.280616
âœ“ Validation MAE: 0.157012
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.04%, Direction Acc: 0.0%

--- Training LSTM for 5-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.084601
âœ“ Validation MAE: 0.041446
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.01%, Direction Acc: 0.0%

--- Training LSTM for 10-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.206577
âœ“ Validation MAE: 0.074437
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.02%, Direction Acc: 0.0%

--- Training LSTM for 15-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.135096
âœ“ Validation MAE: 0.075971
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.02%, Direction Acc: 0.0%

--- Training LSTM for 21-day forecast ---
ğŸ“Š Preparing features...
ğŸ”„ Creating sequences (lookback=60, forecast=7 days)...
âœ“ Training set: 388 samples (each predicts 7 days)
âœ“ Validation set: 97 samples
ğŸ—ï¸ Building multi-output LSTM model (7-day predictions)...
ğŸš€ Training model...
âœ“ Training MAE: 0.177166
âœ“ Validation MAE: 0.130879
  âœ“ Predicted price: 384.00 (+0.00%)
    MAPE: 0.03%, Direction Acc: 0.0%

âœ“ LSTM training completed in 114.97s

================================================================================
TRAINING xLSTM (PyTorch) - Multi-Horizon
================================================================================
âœ“ Loaded 900 days of data
  Date range: 2022-01-09 to 2025-11-27

âœ“ Data prepared
  Train samples: 631
  Test samples: 158
  Horizons: [1, 3, 5, 10, 15, 21]

âœ“ Using device: mps
Building xLSTM forecaster:
  Hidden size: 512
  Num blocks: 7
  Num heads: 8
  Horizons: [1, 3, 5, 10, 15, 21]
Building xLSTM forecaster:
  Hidden size: 512
  Num blocks: 7
  Num heads: 8
  Horizons: [1, 3, 5, 10, 15, 21]

